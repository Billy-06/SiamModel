# -*- coding: utf-8 -*-
"""Copy of Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aY0nMCti7DRcsjzt5x1QSUULrfENw95L
"""

# Required Libraries
import os
import cv2
import shutil
from keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Function to Extract Frames from Videos
def extract_frames(video_path, target_folder, frame_rate=1):
    if not os.path.exists(target_folder):
        os.makedirs(target_folder)

    video = cv2.VideoCapture(video_path)
    count = 0
    frame_count = 0

    while True:
        success, frame = video.read()
        if not success:
            break

        if count % frame_rate == 0:
            frame_path = os.path.join(target_folder, f"frame_{frame_count}.jpg")
            cv2.imwrite(frame_path, frame)
            frame_count += 1

        count += 1

    video.release()
    cv2.destroyAllWindows()

# Function to Create Training and Validation Directories
def create_train_val_dirs(base_dir, categories, train_ratio=0.8):
    train_dir = os.path.join(base_dir, 'train')
    val_dir = os.path.join(base_dir, 'val')

    # Create train and validation main directories
    os.makedirs(train_dir, exist_ok=True)
    os.makedirs(val_dir, exist_ok=True)

    # Create subdirectories for each category
    for category in categories:
        os.makedirs(os.path.join(train_dir, category), exist_ok=True)
        os.makedirs(os.path.join(val_dir, category), exist_ok=True)

    return train_dir, val_dir

# Function to Distribute Frames to Training and Validation Sets
def distribute_frames_to_train_val(extracted_frames_dir, train_dir, val_dir, train_ratio=0.8):
    for category in os.listdir(extracted_frames_dir):
        category_dir = os.path.join(extracted_frames_dir, category)
        frames = os.listdir(category_dir)

        # Split frames into training and validation sets
        train_frames, val_frames = train_test_split(frames, train_size=train_ratio)

        # Copy frames to respective directories
        for frame in train_frames:
            shutil.copy(os.path.join(category_dir, frame), os.path.join(train_dir, category))

        for frame in val_frames:
            shutil.copy(os.path.join(category_dir, frame), os.path.join(val_dir, category))

# Prepare Dataset
dataset_dir = '/content/drive/My Drive/anti-spoofing'
categories = ['mask', 'mask3d', 'monitor', 'outline', 'outline3d', 'real']
extracted_frames_dir = '/content/drive/My Drive/extracted_frames'

for category in categories:
    category_dir = os.path.join(dataset_dir, category)
    output_dir = os.path.join(extracted_frames_dir, category)

    for video_file in os.listdir(category_dir):
        video_path = os.path.join(category_dir, video_file)
        if os.path.isfile(video_path):
            extract_frames(video_path, output_dir)

# Create Training and Validation Directory Structure
base_dir = '/content/drive/My Drive/antispoofing_dataset'
# train_dir, val_dir = create_train_val_dirs(base_dir, categories)

# # Distribute Frames to Training and Validation Directories
# distribute_frames_to_train_val(extracted_frames_dir, train_dir, val_dir)
# Directory paths for training and validation
train_dir = '/content/drive/My Drive/antispoofing_dataset/train'
val_dir = '/content/drive/My Drive/antispoofing_dataset/val'


# Data Augmentation and Preprocessing
from keras.applications.mobilenet_v2 import preprocess_input
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=20,            # Random rotation between 0 and 20 degrees
    width_shift_range=0.2,        # Random horizontal shifts up to 20% of the image width
    height_shift_range=0.2,       # Random vertical shifts up to 20% of the image height
    shear_range=0.2,              # Shear Intensity (Shear angle in counter-clockwise direction in degrees)
    zoom_range=0.2,               # Random zoom range
    horizontal_flip=True,         # Random horizontal flip
    fill_mode='nearest'           # Strategy for filling newly created pixels
)

# Note: For validation data, you usually don't apply data augmentation,
# but you should still preprocess the inputs.
val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

# Flow training images in batches using train_datagen
train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(160, 160),
    batch_size=32,
    class_mode='categorical'
)

# Flow validation images in batches using val_datagen
val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(160, 160),
    batch_size=32,
    class_mode='categorical'
)

# ... [Previous setup code] ...

print('Number of training classes:', len(train_generator.class_indices))
print('Number of validation classes:', len(val_generator.class_indices))

# Import necessary libraries
from keras.models import Model
from keras.layers import Dense, Dropout, GlobalAveragePooling2D
from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input

# Load MobileNetV2 pre-trained on ImageNet, exclude the top layer
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(160, 160, 3))

# Freeze the base model layers
base_model.trainable = False

# Add custom layers on top of MobileNetV2
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(8, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(6, activation='softmax')(x)  # 7 for the number of classes

from keras.callbacks import EarlyStopping
from keras.models import Model



# Final model
model = Model(inputs=base_model.input, outputs=predictions)

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Model Summary
model.summary()

history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=15,  # You can increase this since early stopping is being used
    validation_data=val_generator,
    validation_steps=val_generator.samples // val_generator.batch_size,
    callbacks=[early_stopping]  # Add early stopping here
)

#inference, get the testing function, inference function

# Plotting Training Results (Optional)
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title('Training and Validation Loss')

plt.show()

# Save the model
model_save_path = '/content/drive/My Drive/antispoofing_dataset/saved_model8.h5'
model.save(model_save_path)

print("Model saved to", model_save_path)

import numpy as np
from keras.preprocessing import image
from keras.models import load_model

def load_and_preprocess_image(image_path):
    # Load and preprocess the image for prediction
    img = image.load_img(image_path, target_size=(160, 160))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)
    return img_array

def predict_class(model, image_path):
    # Load and preprocess the image
    processed_image = load_and_preprocess_image(image_path)

    # Make prediction
    predictions = model.predict(processed_image)

    # Get the predicted class index
    predicted_class_index = np.argmax(predictions)

    # Get the class labels from the generator
    class_labels = list(train_generator.class_indices.keys())

    # Get the predicted class label
    predicted_class = class_labels[predicted_class_index]

    # Print "spoof" for certain classes and "real" for 'real' class
    if predicted_class in ['mask', 'mask3d', 'monitor', 'outline', 'outline3d']:
        print("Predicted Class: spoof")
    elif predicted_class == 'real':
        print("Predicted Class: real")
    else:
        print("Unknown class")

    # Also print class probabilities if needed
    print("Class Probabilities:", predictions[0])

# Example usage:
test_image_path = '/content/drive/My Drive/close up.jpg'
predict_class(loaded_model, test_image_path)